{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 0 : Pytorch Fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1053, 0.2695, 0.3588],\n",
      "        [0.1994, 0.5472, 0.0062],\n",
      "        [0.9516, 0.0753, 0.8860],\n",
      "        [0.5832, 0.3376, 0.8090],\n",
      "        [0.5779, 0.9040, 0.5547]])\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#intro to tensors\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gives us the dimensions\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get tensor back as python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a vector \n",
    "vector=torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimensions are defined by the number of [] that exist in the parenthesis\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape is the number of items in each []\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MATRIX\n",
    "MATRIX = torch.tensor([[7,8], [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3, 4],\n",
       "         [4, 5, 6, 5],\n",
       "         [7, 8, 9, 5]],\n",
       "\n",
       "        [[1, 2, 3, 4],\n",
       "         [3, 4, 5, 4],\n",
       "         [2, 3, 4, 4]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TENSOR\n",
    "TENSOR= torch.tensor([ [ [1,2,3,4],[4,5,6,5],[7,8,9,5] ] ,[[1,2,3,4], [3,4,5,4], [2,3,4,4] ], ])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8044, 0.7765, 0.6455, 0.8544],\n",
       "        [0.8262, 0.9842, 0.9249, 0.3605],\n",
       "        [0.8711, 0.6080, 0.0809, 0.3386]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RANDOM TENSORS\n",
    "\n",
    "#random tensors are important because the way most neural networks learn is they start with tensors full of random numbers\n",
    "#and then they adjust those numbers to better represent the data\n",
    "\n",
    "# the flow is the following start with random numbers -> look at data -> update numbers -> look at data etc...\n",
    "\n",
    "#create a random tensor that has size (3,4)\n",
    "random_tensor=torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a random tensor with similar shape to an image tensor\n",
    "random_image_tensor=torch.rand(size=(224,224,3)) #height, width colour channel (R, G, B)\n",
    "random_image_tensor\n",
    "random_image_tensor.shape, random_image_tensor.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor of all zeroes\n",
    "zeros=torch.zeros(3,4)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a range of tensors and tensors-like \n",
    "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros= torch.zeros_like(input=one_to_ten)\n",
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensors datatypes\n",
    "tensor datatype is one of the 3 big errors we encounter in deep learning \n",
    "1. tensor not right datatype\n",
    "2. tensor not right shape\n",
    "3. tensor on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#float_32 tensor\n",
    "float_32_tensor= torch.tensor([1.0,2.0,3.0],\n",
    "                             dtype=None, #defines the data type of he tensor\n",
    "                             device=None, #defines the device the tensor is on \n",
    "                             requires_grad=False #wether or not to track gradients with this tensors operations\n",
    "                            )\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], dtype=torch.float16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor=float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 9.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor*float_16_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get information from tensors\n",
    "1. tensor not right datatype - to get tensors datatype use tensor.dtype\n",
    "2. tensor not right shape - to get a tensors shape use tensor.shape \n",
    "3. tensor on the right device - to get a tensors device use tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5967, 0.7270, 0.4642, 0.9857],\n",
       "        [0.6219, 0.9651, 0.8151, 0.9666],\n",
       "        [0.9827, 0.8628, 0.4643, 0.3154]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing these functions\n",
    "some_tensor=torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatype of tensor is torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(f\"datatype of tensor is {some_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of tensor is torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of tensor is {some_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device of tensor is cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"device of tensor is {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating tensors\n",
    "Common tensor operations : \n",
    "1. addition\n",
    "2. subtraction\n",
    "3. multiplication\n",
    "4. division\n",
    "5. Matric multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#addition\n",
    "tensor=torch.tensor([1,2,3])\n",
    "tensor+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiplication\n",
    "tensor*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subtraction\n",
    "tensor-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.3000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#division\n",
    "tensor/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication\n",
    "Relative info on hoq multiplication in matrices works : https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
    "\n",
    "It needs to satidy 2 conditions :\n",
    "1. The inner dimesions must match examples\n",
    "   (3,2) @ (3,2) WONT WORK\n",
    "   (2,3) @ (3,2) WILL WORK\n",
    "   (3,2) @ (2,3) WILL WORK\n",
    "2. The resulting matrix must have the shape of the OUTER dimensions \n",
    "   (2,3) @ (3,2) -> (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result : tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "#example\n",
    "print(f\"Result : {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      3\u001b[0m tensor1\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      4\u001b[0m                     [\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m],\n\u001b[0;32m      5\u001b[0m                     [\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m]])\n\u001b[0;32m      7\u001b[0m tensor2\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      8\u001b[0m                     [\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m],\n\u001b[0;32m      9\u001b[0m                     [\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m]])\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "### One of the most common errors in Deep Learning : shape errors\n",
    "#example\n",
    "tensor1=torch.tensor([[1,2],\n",
    "                    [4,5],\n",
    "                    [7,8]])\n",
    "\n",
    "tensor2=torch.tensor([[1,2],\n",
    "                    [4,5],\n",
    "                    [7,8]])\n",
    "\n",
    "torch.matmul(tensor1,tensor2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fixing the issue\n",
    "tensor1.shape, tensor2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 4, 7],\n",
       "         [2, 5, 8]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we use a transpose to manipulate the shape of our tensors\n",
    "#it switches the axes of the dimensions\n",
    "tensor1.T, tensor1.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [4, 5],\n",
       "         [7, 8]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1, tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  5,  14,  23],\n",
       "         [ 14,  41,  68],\n",
       "         [ 23,  68, 113]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#matrix multiplication works when tensor2 is transpose\n",
    "torch.matmul(tensor1, tensor2.T), torch.matmul(tensor1, tensor2.T).shape, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor aggragation\n",
    "Finding min,max,sum,mean value etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= torch.arange(0,100,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find min\n",
    "x.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find max\n",
    "x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find mean value\n",
    "#note that mean function requires a tensor of float32 to work so we have to change the datatype in some cases\n",
    "x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(450)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the sum\n",
    "x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the positional min. this means the position in the tensor where the min value is located\n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the positional max. this means the position in the tensor where the max value is located\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking squeezing and un-squeezing tensors\n",
    "Reshaping - reshapes an input tensor into a defined shape\n",
    "View - return a view of an input tensor. Its important to note that the view shares the memory of the original\n",
    "Stacking - combine multiple tensors on top of each other\n",
    "Squeeze - removes all '1' dimensions from a tensor\n",
    "Unsqueeze - adds a '1' dimension to a target tensor\n",
    "Permute - returns a view of the input with the dimesnions permuted (swapped) a cerain way  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]), torch.Size([10]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a tensor\n",
    "x=torch.arange(1.,11.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add an extra dimension \n",
    "#the reshaping has to be compatible with the original size\n",
    "x_reshaped=x.reshape(5,2)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9., 10.]]),\n",
       " tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the view\n",
    "z=x.view(2,5)\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 5.,  2.,  3.,  4.,  5.],\n",
       "         [ 5.,  7.,  8.,  9., 10.]]),\n",
       " tensor([ 5.,  2.,  3.,  4.,  5.,  5.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#changing z also changes x because they share the same memory\n",
    "z[:, 0]=5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.7804],\n",
       "           [0.8824]],\n",
       "\n",
       "          [[0.6983],\n",
       "           [0.1460]]],\n",
       "\n",
       "\n",
       "         [[[0.7804],\n",
       "           [0.8824]],\n",
       "\n",
       "          [[0.6983],\n",
       "           [0.1460]]],\n",
       "\n",
       "\n",
       "         [[[0.7804],\n",
       "           [0.8824]],\n",
       "\n",
       "          [[0.6983],\n",
       "           [0.1460]]],\n",
       "\n",
       "\n",
       "         [[[0.7804],\n",
       "           [0.8824]],\n",
       "\n",
       "          [[0.6983],\n",
       "           [0.1460]]]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack tensors on top of each other\n",
    "x_stacked=torch.stack([x,x,x,x], dim=1)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.5795],\n",
       "           [0.0999]],\n",
       " \n",
       "          [[0.0666],\n",
       "           [0.4159]]]]),\n",
       " torch.Size([1, 2, 2, 1]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand(1,2,2,1)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5795, 0.0999],\n",
       "         [0.0666, 0.4159]]),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#squeeze removes all single dimensions from target tensor\n",
    "x_squeezed=torch.squeeze(x)\n",
    "x_squeezed, x_squeezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous target tensor([[0.5795, 0.0999],\n",
      "        [0.0666, 0.4159]])\n",
      "previous shape torch.Size([2, 2])\n",
      "current target tensor([[[0.5795, 0.0999],\n",
      "         [0.0666, 0.4159]]])\n",
      "current shape torch.Size([1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "#unsqueeze adds a single dimension to a tensor target\n",
    "print(f\"previous target {x_squeezed}\")\n",
    "print(f\"previous shape {x_squeezed.shape}\")\n",
    "\n",
    "x_unsqueezed=x_squeezed.unsqueeze(dim=0)\n",
    "\n",
    "print(f\"current target {x_unsqueezed}\")\n",
    "print(f\"current shape {x_unsqueezed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous target tensor([[[[0.5795],\n",
      "          [0.0999]],\n",
      "\n",
      "         [[0.0666],\n",
      "          [0.4159]]]])\n",
      "previous shape torch.Size([1, 2, 2, 1])\n",
      "current target tensor([[[[0.5795, 0.0666]],\n",
      "\n",
      "         [[0.0999, 0.4159]]]])\n",
      "current shape torch.Size([1, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "#permute swaps the dimensions of a given tensor input\n",
    "#permute is also a view wich means it shares the same memory as the original\n",
    "#any changes in permuted tensor affect the original \n",
    "print(f\"previous target {x}\")\n",
    "print(f\"previous shape {x.shape}\")\n",
    "\n",
    "x_permuted=x.permute(3,2,0,1)\n",
    "\n",
    "print(f\"current target {x_permuted}\")\n",
    "print(f\"current shape {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing in Pytorch\n",
    "Its similar to indexing in NumPy\n",
    "\n",
    "pytorch is compaible with numpy \n",
    "\n",
    "* data in numpy, want in pytorch tensor -> torch.from_numpy(ndarray)\n",
    "\n",
    "* conver pytorch tensor to numpy data -> torch.Tensor.numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create example tensor\n",
    "tensor=torch.arange(1,10).reshape(1,3,3)\n",
    "tensor, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets index on our new tensor\n",
    "tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can use : to select \"all\" of a target dimension\n",
    "tensor[: , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all the values from 0th and 1st dimension but only index 2 of dimension 2\n",
    "tensor[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all values from 0th dimension but only index 1 from 1st dimension and index 2 from 2nd\n",
    "tensor[:,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get 1 index from 0th and 1st dimension and all values from 2nd dimension\n",
    "tensor[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data conversion from pytorch to numpy\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "array=np.arange(1.0, 8.0)\n",
    "tensor=torch.from_numpy(array)\n",
    "\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducability (take random out of random)\n",
    "how a neural network learns :\n",
    "1) Start with random numbers\n",
    "2) Tensor operations to update random numbers and try to make them better representaions of the data\n",
    "3) Repeat step 2 constantly\n",
    "\n",
    "To reduce the randomness in neural netoworks in Pytorch comes the concept of *random seed*. Essentially what it does is **flavour** the randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "#example of random and unreproducable tensors\n",
    "import torch \n",
    "\n",
    "t_a=torch.rand(3,4)\n",
    "\n",
    "t_b=torch.rand(3,4)\n",
    "\n",
    "print(t_a)\n",
    "print(t_b)\n",
    "print(t_a==t_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "#lets make some random but reproducable tensors\n",
    "import torch \n",
    "\n",
    "RANDOM_SEED=42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "t_c=torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "t_d=torch.rand(3,4)\n",
    "\n",
    "print(t_c)\n",
    "print(t_d)\n",
    "print(t_c==t_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra resources for reproducability : https://pytorch.org/docs/stable/notes/randomness.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
